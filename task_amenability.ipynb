{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPmwRIpXGqCySSInDl81gCH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YolandaMDavis/wildtrack-iqa/blob/task-amenability/task_amenability.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "d4TSq2CVs964",
        "outputId": "a1a58176-bb7c-4140-b1da-0e843b3d1c32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'model.pt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "#Only needed to copy data to local drive can be skipped if zip file is already available in working folder\n",
        "import shutil\n",
        "\n",
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # for google colab. adjust accordingly\n",
        "PARENT_DIR = '/content/drive/MyDrive/Wildtrack Group/IQA' \n",
        "\n",
        "# copy and extract tar file\n",
        "shutil.copy(PARENT_DIR + '/data/WildTrack_Raw.zip', 'WildTrack_Raw.zip')\n",
        "\n",
        "# get downstream task model\n",
        "shutil.copy(PARENT_DIR + '/task-amenability/model.pt', 'model.pt')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clone the repository and move data file\n",
        "!git clone https://github.com/YolandaMDavis/wildtrack-iqa.git\n",
        "!mv WildTrack_Raw.zip wildtrack-iqa/.\n",
        "!mv model.pt wildtrack-iqa/.\n",
        "%cd \"wildtrack-iqa\"\n",
        "!git checkout task-amenability\n",
        "!mv model.pt taskamenability/taskpredictor/.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyJm9Cb5t0d8",
        "outputId": "d8326416-3824-421e-9df0-255f4d4b08bb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'wildtrack-iqa'...\n",
            "remote: Enumerating objects: 69, done.\u001b[K\n",
            "remote: Counting objects: 100% (69/69), done.\u001b[K\n",
            "remote: Compressing objects: 100% (53/53), done.\u001b[K\n",
            "remote: Total 69 (delta 21), reused 56 (delta 12), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (69/69), done.\n",
            "/content/wildtrack-iqa\n",
            "Branch 'task-amenability' set up to track remote branch 'task-amenability' from 'origin'.\n",
            "Switched to a new branch 'task-amenability'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "# extract zip file\n",
        "with ZipFile('WildTrack_Raw.zip', 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zipObj.extractall()"
      ],
      "metadata": {
        "id": "Av0a2a-HwCvC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"wildtrack-iqa\"\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import json\n",
        "import numpy as np\n",
        "import albumentations as A\n",
        "\n",
        "with open('taskamenability/taskpredictor/class_mapping.json') as data:\n",
        "    mappings = json.load(data)\n",
        "\n",
        "class_mapping = {item['model_idx']: item['class_name'] for item in mappings}\n",
        "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device = torch.device('cpu')\n",
        "model = torch.jit.load('taskamenability/taskpredictor/model.pt').to(device)\n",
        "transforms = A.load('taskamenability/taskpredictor/transforms.json')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmHIUgZBzneZ",
        "outputId": "baba2ae5-f09d-4cf4-c206-70dc965d7993"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/wildtrack-iqa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils import data\n",
        "import csv\n",
        "import random\n",
        "import torch\n",
        "import yaml\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "from time import process_time\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "root_dir = '/content/wildtrack-iqa'\n",
        "data_dir = root_dir + '/RAW'\n",
        "\n",
        "def generate_data_files(sample_percentage=1):\n",
        "\n",
        "    image_reference_list = []\n",
        "\n",
        "    subdirectories = list(os.walk(data_dir, topdown=False))[:-1]\n",
        "    for subdir in subdirectories:\n",
        "        image_location = subdir[0]\n",
        "        images = subdir[2]\n",
        "        species_rating = image_location.rsplit('/', 1)[-1].replace('_', ' ')\n",
        "        score = int(species_rating.rsplit(' ', 1)[-1])\n",
        "        species_class = species_rating.rsplit(' ', 1)[:-1][0]\n",
        "        if len(species_class.rsplit(' ', 1)) > 1:\n",
        "            species = species_class.rsplit(' ')[0]\n",
        "            animal_class = ' '.join(species_class.rsplit(' ')[1:])\n",
        "        else:\n",
        "            animal_class = 'Unknown'\n",
        "            species = species_class\n",
        "\n",
        "        for image in images:\n",
        "            image_reference = (image_location, species, animal_class, image, score)\n",
        "            image_reference_list.append(image_reference)\n",
        "        \n",
        "\n",
        "    # shuffle then split\n",
        "    seed = 1234\n",
        "    random.Random(seed).shuffle(image_reference_list)\n",
        "\n",
        "    train_index = int(len(image_reference_list) *0.6 *sample_percentage)\n",
        "    test_index = -int(len(image_reference_list) * 0.2 * sample_percentage) \n",
        "    val_index = test_index * 2\n",
        "\n",
        "    training = image_reference_list[:train_index]\n",
        "    validation = image_reference_list[val_index:test_index]\n",
        "    testing = image_reference_list[test_index:]\n",
        "    return training, validation, testing\n",
        "\n",
        "def convert_image(img_test):\n",
        "    image = Image.open(img_test)\n",
        "    image = image.resize((1024, 768))\n",
        "    image = np.array(image)\n",
        "    image = transforms(image=image)['image']\n",
        "    x = torch.from_numpy(image).to(device)\n",
        "    return x\n",
        "\n",
        "\n",
        "def transform_images(images):\n",
        "    x = np.array([convert_image(img[0]+'/'+img[3]) for img in images])\n",
        "    y = np.array([0 if img[4] < 4 else 1 for img in images ])\n",
        "    return x, y\n"
      ],
      "metadata": {
        "id": "4pAwja3NgWqL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# take a percentage of the full data set as a training/test/validation sample\n",
        "sample_size=.01\n",
        "train, valid, test = generate_data_files(sample_size)\n",
        "x_train, y_train = transform_images(train)\n",
        "x_val, y_val = transform_images(valid)\n",
        "x_test, y_test = transform_images(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8GdSg7AieRs",
        "outputId": "d80ecf04-af08-445e-f702-96b8bd2449b0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Execute the below installation only in Colab environment**"
      ],
      "metadata": {
        "id": "-N-KhCLnnRqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gym==0.17.3\n",
        "!pip install stable-baselines==2.10.2\n",
        "!pip install h5py==3.0.0\n",
        "!pip install tensorflow==1.13.1\n",
        "!pip install tensorboard==1.13.1\n",
        "!pip install Keras==2.2.4\n",
        "!pip install Keras-Applications==1.0.8\n",
        "!pip install Keras-Preprocessing==1.1.2\n",
        "!pip install keras-rl==0.4.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSVzE5j73Zsf",
        "outputId": "964dbd53-546e-4bba-9b79-65c654445145"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gym==0.17.3\n",
            "  Downloading gym-0.17.3.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 33.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym==0.17.3) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym==0.17.3) (1.21.6)\n",
            "Collecting pyglet<=1.5.0,>=1.4.0\n",
            "  Downloading pyglet-1.5.0-py2.py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 80.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym==0.17.3) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym==0.17.3) (0.16.0)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.17.3-py3-none-any.whl size=1654653 sha256=07300996ad4112a543b6ba2b60452523275c8c6e2395c1ba183a5f3c58a6d653\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/81/4b/dd9c029691022cb957398d1f015e66b75e37637dda61abdf58\n",
            "Successfully built gym\n",
            "Installing collected packages: pyglet, gym\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "Successfully installed gym-0.17.3 pyglet-1.5.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting stable-baselines==2.10.2\n",
            "  Downloading stable_baselines-2.10.2-py3-none-any.whl (240 kB)\n",
            "\u001b[K     |████████████████████████████████| 240 kB 27.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable-baselines==2.10.2) (1.3.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from stable-baselines==2.10.2) (1.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stable-baselines==2.10.2) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from stable-baselines==2.10.2) (1.7.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable-baselines==2.10.2) (3.2.2)\n",
            "Requirement already satisfied: gym[atari,classic_control]>=0.11 in /usr/local/lib/python3.7/dist-packages (from stable-baselines==2.10.2) (0.17.3)\n",
            "Requirement already satisfied: cloudpickle>=0.5.5 in /usr/local/lib/python3.7/dist-packages (from stable-baselines==2.10.2) (1.5.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from stable-baselines==2.10.2) (4.6.0.66)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines==2.10.2) (1.5.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines==2.10.2) (7.1.2)\n",
            "Requirement already satisfied: atari-py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines==2.10.2) (0.2.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from atari-py~=0.2.0->gym[atari,classic_control]>=0.11->stable-baselines==2.10.2) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari,classic_control]>=0.11->stable-baselines==2.10.2) (0.16.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines==2.10.2) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines==2.10.2) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines==2.10.2) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines==2.10.2) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->stable-baselines==2.10.2) (4.1.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->stable-baselines==2.10.2) (2022.4)\n",
            "Installing collected packages: stable-baselines\n",
            "Successfully installed stable-baselines-2.10.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting h5py==3.0.0\n",
            "  Downloading h5py-3.0.0-cp37-cp37m-manylinux1_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 37.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py==3.0.0) (1.21.6)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py==3.0.0) (1.5.2)\n",
            "Installing collected packages: h5py\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "Successfully installed h5py-3.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==1.13.1\n",
            "  Downloading tensorflow-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (92.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 92.6 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.5.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.21.6)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.8.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.49.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.2.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.37.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.15.0)\n",
            "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
            "  Downloading tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367 kB)\n",
            "\u001b[K     |████████████████████████████████| 367 kB 86.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (2.0.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (3.17.3)\n",
            "Collecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 8.2 MB/s \n",
            "\u001b[?25hCollecting tensorboard<1.14.0,>=1.13.0\n",
            "  Downloading tensorboard-1.13.1-py3-none-any.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 77.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (3.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (5.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (4.1.1)\n",
            "Collecting mock>=2.0.0\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.13.1) (1.5.2)\n",
            "Installing collected packages: mock, tensorflow-estimator, tensorboard, keras-applications, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220929150707\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220929150707:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220929150707\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.13.1 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-applications-1.0.8 mock-4.0.3 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorboard==1.13.1 in /usr/local/lib/python3.7/dist-packages (1.13.1)\n",
            "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.13.1) (1.49.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.13.1) (1.21.6)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.13.1) (1.15.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.13.1) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.13.1) (0.37.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.13.1) (1.2.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.13.1) (3.17.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.13.1) (3.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard==1.13.1) (5.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard==1.13.1) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard==1.13.1) (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Keras==2.2.4\n",
            "  Downloading Keras-2.2.4-py2.py3-none-any.whl (312 kB)\n",
            "\u001b[K     |████████████████████████████████| 312 kB 35.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from Keras==2.2.4) (1.7.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras==2.2.4) (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from Keras==2.2.4) (1.21.6)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from Keras==2.2.4) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras==2.2.4) (6.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from Keras==2.2.4) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from Keras==2.2.4) (1.1.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->Keras==2.2.4) (1.5.2)\n",
            "Installing collected packages: Keras\n",
            "  Attempting uninstall: Keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "Successfully installed Keras-2.2.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Keras-Applications==1.0.8 in /usr/local/lib/python3.7/dist-packages (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras-Applications==1.0.8) (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from Keras-Applications==1.0.8) (1.21.6)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->Keras-Applications==1.0.8) (1.5.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Keras-Preprocessing==1.1.2 in /usr/local/lib/python3.7/dist-packages (1.1.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from Keras-Preprocessing==1.1.2) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from Keras-Preprocessing==1.1.2) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-rl==0.4.2\n",
            "  Downloading keras-rl-0.4.2.tar.gz (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras>=2.0.7 in /usr/local/lib/python3.7/dist-packages (from keras-rl==0.4.2) (2.2.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.7->keras-rl==0.4.2) (3.0.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.7->keras-rl==0.4.2) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.7->keras-rl==0.4.2) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.7->keras-rl==0.4.2) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.7->keras-rl==0.4.2) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.7->keras-rl==0.4.2) (1.7.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.7->keras-rl==0.4.2) (6.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras>=2.0.7->keras-rl==0.4.2) (1.5.2)\n",
            "Building wheels for collected packages: keras-rl\n",
            "  Building wheel for keras-rl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-rl: filename=keras_rl-0.4.2-py3-none-any.whl size=48378 sha256=e3458659ecdb1468ac67dd4116d690407e6796b65849ca7119183d9c4243ce91\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/23/e9/278c2e59c322236e2bfdf7c792c16f0b4dec24816d27a3f1e4\n",
            "Successfully built keras-rl\n",
            "Installing collected packages: keras-rl\n",
            "Successfully installed keras-rl-0.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from taskamenability.interface import PPOInterface\n",
        "\n",
        "img_shape = (416,555,3)\n",
        "task_predictor = model\n",
        "interface = PPOInterface(x_train, y_train, x_val, y_val, x_test, y_test, task_predictor, img_shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxSl5aC2xE3u",
        "outputId": "745e656b-d40e-449f-fe1d-57e6d63dd374"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/stable_baselines/__init__.py:33: UserWarning: stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\n",
            "  \"stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\"\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interface.train(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnmi6hBOOyka",
        "outputId": "156d7602-db22-43e5-bcc1-bf0c6a99fe5c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training started for 2 episodes:\n",
            "test this out\n",
            "Predicted Action: What Images Should be Used vs Not\n",
            "[array([1.], dtype=float32), array([1.], dtype=float32), array([1.], dtype=float32), array([1.], dtype=float32), array([1.], dtype=float32), array([1.], dtype=float32), array([1.], dtype=float32), array([1.], dtype=float32), array([1.], dtype=float32)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:1130: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
            "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:594.)\n",
            "  return forward_call(*input, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:1130: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
            "  return forward_call(*input, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:1130: UserWarning: operator() sees varying value in profiling, ignoring and this should be handled by GUARD logic (Triggered internally at  ../torch/csrc/jit/codegen/cuda/parser.cpp:3513.)\n",
            "  return forward_call(*input, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'pred_classes': tensor([0]), 'scores': tensor([0.9985]), 'pred_boxes': tensor([[ 99.2085,  44.2886, 442.6307, 264.8299]])}\n",
            "(1, array([1]))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:1130: UserWarning: operator() profile_node %248 : int = prim::profile_ivalue(%out_dtype.8)\n",
            " does not have profile information (Triggered internally at  ../torch/csrc/jit/codegen/cuda/graph_fuser.cpp:104.)\n",
            "  return forward_call(*input, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'pred_classes': tensor([0, 0]), 'scores': tensor([0.9713, 0.6345]), 'pred_boxes': tensor([[201.9142, 147.0838, 455.4426, 311.4117],\n",
            "        [ 87.0187,  80.4855, 251.4566, 234.8643]])}\n",
            "(1, array([1]))\n",
            "{'pred_classes': tensor([0]), 'scores': tensor([0.9977]), 'pred_boxes': tensor([[135.0040,  15.6196, 520.8668, 303.3041]])}\n",
            "(1, array([0]))\n",
            "{'pred_classes': tensor([0]), 'scores': tensor([0.9535]), 'pred_boxes': tensor([[177.2644, 233.8972, 330.5865, 334.7251]])}\n",
            "(1, array([0]))\n",
            "{'pred_classes': tensor([0]), 'scores': tensor([0.9983]), 'pred_boxes': tensor([[ 62.8145,  58.9444, 447.6633, 357.7259]])}\n",
            "(1, array([1]))\n",
            "{'pred_classes': tensor([0]), 'scores': tensor([0.9763]), 'pred_boxes': tensor([[142.4867,  77.8004, 452.4843, 316.9387]])}\n",
            "(1, array([0]))\n",
            "{'pred_classes': tensor([0, 0, 0]), 'scores': tensor([0.9914, 0.2011, 0.0725]), 'pred_boxes': tensor([[193.5932,  89.5177, 467.7228, 292.7657],\n",
            "        [166.5195,  83.6837, 338.7125, 266.8720],\n",
            "        [ 61.8758,  74.1864, 411.3309, 287.8017]])}\n",
            "(1, array([0]))\n",
            "{'pred_classes': tensor([0]), 'scores': tensor([0.9974]), 'pred_boxes': tensor([[ 43.4605,  20.8954, 445.8962, 306.1944]])}\n",
            "(1, array([0]))\n",
            "{'pred_classes': tensor([0]), 'scores': tensor([0.9722]), 'pred_boxes': tensor([[163.1111, 130.3738, 370.6838, 283.9426]])}\n",
            "(1, array([0]))\n",
            "[1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
            "test this out\n",
            "-----------------------------------\n",
            "| approxkl           | 10.301651  |\n",
            "| clipfrac           | 0.75       |\n",
            "| explained_variance | -33        |\n",
            "| fps                | 0          |\n",
            "| n_updates          | 1          |\n",
            "| policy_entropy     | 1.4189384  |\n",
            "| policy_loss        | 0.22610772 |\n",
            "| serial_timesteps   | 17         |\n",
            "| time_elapsed       | 1.43e-05   |\n",
            "| total_timesteps    | 17         |\n",
            "| value_loss         | 6370439.0  |\n",
            "-----------------------------------\n",
            "Predicted Action: What Images Should be Used vs Not\n",
            "[array([1.], dtype=float32), array([1.], dtype=float32), array([1.], dtype=float32), array([1.], dtype=float32), array([1.], dtype=float32), array([1.], dtype=float32), array([1.], dtype=float32), array([1.], dtype=float32), array([1.], dtype=float32)]\n",
            "{'pred_classes': tensor([0]), 'scores': tensor([0.9985]), 'pred_boxes': tensor([[ 99.2085,  44.2886, 442.6307, 264.8299]])}\n",
            "(1, array([1]))\n",
            "{'pred_classes': tensor([0, 0]), 'scores': tensor([0.9713, 0.6345]), 'pred_boxes': tensor([[201.9142, 147.0838, 455.4426, 311.4117],\n",
            "        [ 87.0187,  80.4855, 251.4566, 234.8643]])}\n",
            "(1, array([1]))\n",
            "{'pred_classes': tensor([0]), 'scores': tensor([0.9977]), 'pred_boxes': tensor([[135.0040,  15.6196, 520.8668, 303.3041]])}\n",
            "(1, array([0]))\n",
            "{'pred_classes': tensor([0]), 'scores': tensor([0.9535]), 'pred_boxes': tensor([[177.2644, 233.8972, 330.5865, 334.7251]])}\n",
            "(1, array([0]))\n",
            "{'pred_classes': tensor([0]), 'scores': tensor([0.9983]), 'pred_boxes': tensor([[ 62.8145,  58.9444, 447.6633, 357.7259]])}\n",
            "(1, array([1]))\n",
            "{'pred_classes': tensor([0]), 'scores': tensor([0.9763]), 'pred_boxes': tensor([[142.4867,  77.8004, 452.4843, 316.9387]])}\n",
            "(1, array([0]))\n",
            "{'pred_classes': tensor([0, 0, 0]), 'scores': tensor([0.9914, 0.2011, 0.0725]), 'pred_boxes': tensor([[193.5932,  89.5177, 467.7228, 292.7657],\n",
            "        [166.5195,  83.6837, 338.7125, 266.8720],\n",
            "        [ 61.8758,  74.1864, 411.3309, 287.8017]])}\n",
            "(1, array([0]))\n",
            "{'pred_classes': tensor([0]), 'scores': tensor([0.9974]), 'pred_boxes': tensor([[ 43.4605,  20.8954, 445.8962, 306.1944]])}\n",
            "(1, array([0]))\n",
            "{'pred_classes': tensor([0]), 'scores': tensor([0.9722]), 'pred_boxes': tensor([[163.1111, 130.3738, 370.6838, 283.9426]])}\n",
            "(1, array([0]))\n",
            "[1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
            "test this out\n",
            "-----------------------------------\n",
            "| approxkl           | 97.21558   |\n",
            "| clipfrac           | 0.5735294  |\n",
            "| explained_variance | -0.722     |\n",
            "| fps                | 1          |\n",
            "| n_updates          | 2          |\n",
            "| policy_entropy     | 1.4189355  |\n",
            "| policy_loss        | 0.21066925 |\n",
            "| serial_timesteps   | 34         |\n",
            "| time_elapsed       | 26.8       |\n",
            "| total_timesteps    | 34         |\n",
            "| value_loss         | 660751.06  |\n",
            "-----------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# how to extract quality mode from interface and use for prediction\n",
        "# eventually this should be a pytorch model and we'll need to account"
      ],
      "metadata": {
        "id": "flmF4Ned5oas"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}