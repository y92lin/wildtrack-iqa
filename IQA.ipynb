{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO6mWBOPlVKW7xovVK/W+64",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YolandaMDavis/wildtrack-iqa/blob/additional-tuning/IQA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Image Quality Assessment**\n",
        "\n"
      ],
      "metadata": {
        "id": "K6zCGmX_J5oI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Required Libraries"
      ],
      "metadata": {
        "id": "1inriv8QKR2N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfUbKma6J0fH",
        "outputId": "6aac5b37-3b4f-4af9-b664-ad45f9f9951c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.6 MB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 47.3 MB/s \n",
            "\u001b[?25h  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 240 kB 4.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 5.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 92.6 MB 1.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 49.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 367 kB 57.0 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[?25hLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement Keras==2.2.--quiet (from versions: 0.2.0, 0.3.0, 0.3.1, 0.3.2, 0.3.3, 1.0.0, 1.0.1, 1.0.2, 1.0.3, 1.0.4, 1.0.5, 1.0.6, 1.0.7, 1.0.8, 1.1.0, 1.1.1, 1.1.2, 1.2.0, 1.2.1, 1.2.2, 2.0.0, 2.0.1, 2.0.2, 2.0.3, 2.0.4, 2.0.5, 2.0.6, 2.0.7, 2.0.8, 2.0.9, 2.1.0, 2.1.1, 2.1.2, 2.1.3, 2.1.4, 2.1.5, 2.1.6, 2.2.0, 2.2.1, 2.2.2, 2.2.3, 2.2.4, 2.2.5, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.4.2, 2.4.3, 2.5.0rc0, 2.6.0rc0, 2.6.0rc1, 2.6.0rc2, 2.6.0rc3, 2.6.0, 2.7.0rc0, 2.7.0rc2, 2.7.0, 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.10.0rc0, 2.10.0rc1, 2.10.0, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0rc3, 2.11.0)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for Keras==2.2.--quiet\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Keras-Applications==1.0.8 in /usr/local/lib/python3.7/dist-packages (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from Keras-Applications==1.0.8) (1.21.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras-Applications==1.0.8) (3.0.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->Keras-Applications==1.0.8) (1.5.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Keras-Preprocessing==1.1.2 in /usr/local/lib/python3.7/dist-packages (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from Keras-Preprocessing==1.1.2) (1.21.6)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from Keras-Preprocessing==1.1.2) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-rl==0.4.2\n",
            "  Downloading keras-rl-0.4.2.tar.gz (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 3.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras>=2.0.7 in /usr/local/lib/python3.7/dist-packages (from keras-rl==0.4.2) (2.9.0)\n",
            "Building wheels for collected packages: keras-rl\n",
            "  Building wheel for keras-rl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-rl: filename=keras_rl-0.4.2-py3-none-any.whl size=48380 sha256=33e5d3b92ea04848ae411489543b01560ecb4d9bccfa941587d7d0214ea4e313\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/23/e9/278c2e59c322236e2bfdf7c792c16f0b4dec24816d27a3f1e4\n",
            "Successfully built keras-rl\n",
            "Installing collected packages: keras-rl\n",
            "Successfully installed keras-rl-0.4.2\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "!pip install gym==0.17.3 --quiet\n",
        "!pip install stable-baselines==2.10.2 --quiet\n",
        "!pip install h5py==3.0.0 --quiet\n",
        "!pip install tensorflow==1.13.1 --quiet\n",
        "!pip install tensorboard==1.13.1 --quiet\n",
        "!pip install Keras==2.2.--quiet\n",
        "!pip install Keras-Applications==1.0.8 --quiet\n",
        "!pip install Keras-Preprocessing==1.1.2 --quiet\n",
        "!pip install keras-rl==0.4.2 --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Copy Model Library and Transformation File to Local Drive\n"
      ],
      "metadata": {
        "id": "s2wrDpZTKjWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "\n",
        "drive.mount('/content/drive') # for google colab. adjust accordingly\n",
        "PARENT_DIR = '/content/drive/MyDrive/Wildtrack Group/IQA' \n",
        "\n",
        "\n",
        "# copy model files\n",
        "shutil.copy(PARENT_DIR + '/final_model/final_model.zip','final_model.zip')\n",
        "shutil.copy(PARENT_DIR + '/final_model/transforms.json','transforms.json')\n",
        "\n",
        "# get downstream/classification task model files\n",
        "shutil.copy(PARENT_DIR + '/final_model/species_model.pt', 'species_model.pt')\n",
        "shutil.copy(PARENT_DIR + '/final_model/class_mapping.json', 'class_mapping.json')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "hSY-gKeCKQX2",
        "outputId": "52c45964-1d20-4835-c37f-6642d8888f0b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'class_mapping.json'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy and Expand Sample Images"
      ],
      "metadata": {
        "id": "vd1SVEATU4WP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "# copy annotated and cropped images imafea\n",
        "shutil.copy(PARENT_DIR + '/data/Annotated_Cropped_WildTrack.zip', 'Cropped_WildTrack.zip')\n",
        "\n",
        "# extract zip file\n",
        "with ZipFile('Cropped_WildTrack.zip', 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zipObj.extractall()"
      ],
      "metadata": {
        "id": "uv7ULe8IU3jj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Image Conversion functions for Model"
      ],
      "metadata": {
        "id": "Vnfx58iYSOcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "import albumentations as A\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import os\n",
        "\n",
        "transforms = A.load('transforms.json')\n",
        "data_dir = 'RAW/'\n",
        "\n",
        "#load pictures into memory\n",
        "def convert_image(img_path):\n",
        "    image = Image.open(img_path)\n",
        "    bands = image.getbands()\n",
        "    if len(bands) == 1:\n",
        "      image = image.convert(mode='RGB')\n",
        "    image = np.array(image)\n",
        "    image = transforms(image=image)['image']\n",
        "    return np.array([image])\n",
        "\n",
        "#Obtain random images for prediction\n",
        "def select_random_image():\n",
        "  subdirectories = list(os.walk(data_dir, topdown=False))[:-1]\n",
        "  while True:\n",
        "    subdir = random.choice(subdirectories)\n",
        "    if len(subdir) > 0 and len(subdir[2]) > 0:\n",
        "      species_rating = subdir[0].rsplit('/', 1)[-1].replace('_', ' ')\n",
        "      species_class = species_rating.rsplit(' ', 1)[:-1][0]\n",
        "      image_name = subdir[0] +'/'+ subdir[2][0]\n",
        "      return image_name, convert_image(image_name), species_class\n",
        "\n",
        "# retrieve dictionary key given value\n",
        "def get_key(val, item_dict):\n",
        "    for key, value in item_dict.items():\n",
        "        if val == value:\n",
        "            return key\n",
        "    return -1\n",
        "    "
      ],
      "metadata": {
        "id": "4KH7e5bgOWOh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load IQA Model"
      ],
      "metadata": {
        "id": "qxuwRGDeND1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines import PPO2\n",
        "\n",
        "# import model for inference\n",
        "quality_model = PPO2.load('final_model.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSWSHiJ-J4Qn",
        "outputId": "b8ad8d52-56bc-41ee-fa68-c540bfb0f3b7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading a model without an environment, this model cannot be trained until it has a valid environment.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Species Classification Model"
      ],
      "metadata": {
        "id": "KYAq-5FSFbxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Species Classification Model\n",
        "import torch\n",
        "import json\n",
        "\n",
        "device = \"cpu\"\n",
        "species_model = torch.jit.load('species_model.pt').to(device)\n",
        "\n",
        "with open('class_mapping.json') as data:\n",
        "    mappings = json.load(data)\n",
        "\n",
        "class_mapping = {item['model_idx']: item['class_name'] for item in mappings}\n"
      ],
      "metadata": {
        "id": "5xnqb-QS1yMS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sample Image Predictions"
      ],
      "metadata": {
        "id": "KsJt47GH7NZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Try 10 Random Imaages to assess classification performance\n",
        "image_predictions = []\n",
        "\n",
        "for i in range(10):\n",
        "  image_name, image, species_class = select_random_image()\n",
        "  image = torch.from_numpy(image).to(\"cpu\")\n",
        "  prediction = quality_model.predict(image)[0]\n",
        "  prediction_string = \"Usable\" if np.rint(np.array(prediction).flatten())[0] > 0 else \"Not Usable\"\n",
        "  print('Prediction for image {0}:  {1}\\n'.format(image_name, prediction_string))\n",
        "\n",
        "  if len(species_class.rsplit(' ', 1)) > 1:\n",
        "      species = species_class.rsplit(' ')[0]\n",
        "      animal_class = ' '.join(species_class.rsplit(' ')[1:])\n",
        "  else:\n",
        "      animal_class = 'Unknown'\n",
        "      species = species_class\n",
        "\n",
        "  class_name = species if animal_class == 'Unknown' else species + ': ' + animal_class\n",
        "  class_idx = get_key(class_name, class_mapping)\n",
        "\n",
        "  image_predictions.append((image_name, image[0], class_idx, prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7rKmcGXrefv",
        "outputId": "35abe5f4-d2dc-4508-d755-67cb453fc5e0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction for image RAW/Leopard_African_3/ed818924ce0911ea9d650242ac110002_.jpg:  Usable\n",
            "\n",
            "Prediction for image RAW/Puma_4/af9fb6cad3dd11ea91590242ac1c0002_.jpg:  Usable\n",
            "\n",
            "Prediction for image RAW/Tiger_Bengal_3/8e66129e221e11eb9d950242ac110002_.jpg:  Usable\n",
            "\n",
            "Prediction for image RAW/Jaguar_3/cdeb03f0bfcd11eba8a200155d2c01bc_.jpg:  Usable\n",
            "\n",
            "Prediction for image RAW/Rhino_White_5/e90c8b04d3dd11ea91590242ac1c0002_.jpg:  Usable\n",
            "\n",
            "Prediction for image RAW/Tiger_Bengal_3/8e66129e221e11eb9d950242ac110002_.jpg:  Not Usable\n",
            "\n",
            "Prediction for image RAW/Elephant_African_5/30501b94c0fa11ea82a50242ac1c0002_.jpg:  Usable\n",
            "\n",
            "Prediction for image RAW/Jaguar_4/c8532248f3c111ea9d950242ac110002_.jpg:  Usable\n",
            "\n",
            "Prediction for image RAW/Tapir_Lowland_3/725f3d62d3dd11ea91590242ac1c0002_.jpg:  Usable\n",
            "\n",
            "Prediction for image RAW/Puma_4/af9fb6cad3dd11ea91590242ac1c0002_.jpg:  Usable\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Image Prediction with Species Classification"
      ],
      "metadata": {
        "id": "YIt7DV5b7R6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate images with species classification model\n",
        "\n",
        "for image_prediction in image_predictions:\n",
        "  image_name = image_prediction[0]\n",
        "  image = image_prediction[1]\n",
        "  y_true = image_prediction[2]\n",
        "  quality = image_prediction[3]\n",
        "  obs = image.permute(2, 0, 1).unsqueeze(dim=0).float()\n",
        "  y_pred = species_model(obs)\n",
        "  y_pred = y_pred.argmax(dim=1).squeeze().item()\n",
        "\n",
        "  if y_true == y_pred and quality == 1:\n",
        "    print('Image {0} was predicted as Usable and could be classified.\\n'.format(image_name))\n",
        "  elif y_true != y_pred and quality == 0:\n",
        "    print('Image {0} was predicted as Not Usable and could not be classified, as predicted.\\n'.format(image_name))\n",
        "  else:\n",
        "    print('Quality prediction for Image {0} was not successful\\n'.format(image_name))  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pomz2HRH-Vte",
        "outputId": "5ab6ef22-4d21-42e2-fa9d-35fd10ad3139"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image RAW/Leopard_African_3/ed818924ce0911ea9d650242ac110002_.jpg was predicted as Usable and could be classified.\n",
            "\n",
            "Image RAW/Puma_4/af9fb6cad3dd11ea91590242ac1c0002_.jpg was predicted as Usable and could be classified.\n",
            "\n",
            "Image RAW/Tiger_Bengal_3/8e66129e221e11eb9d950242ac110002_.jpg was predicted as Usable and could be classified.\n",
            "\n",
            "Image RAW/Jaguar_3/cdeb03f0bfcd11eba8a200155d2c01bc_.jpg was predicted as Usable and could be classified.\n",
            "\n",
            "Image RAW/Rhino_White_5/e90c8b04d3dd11ea91590242ac1c0002_.jpg was predicted as Usable and could be classified.\n",
            "\n",
            "Quality prediction for Image RAW/Tiger_Bengal_3/8e66129e221e11eb9d950242ac110002_.jpg was not successful\n",
            "\n",
            "Image RAW/Elephant_African_5/30501b94c0fa11ea82a50242ac1c0002_.jpg was predicted as Usable and could be classified.\n",
            "\n",
            "Image RAW/Jaguar_4/c8532248f3c111ea9d950242ac110002_.jpg was predicted as Usable and could be classified.\n",
            "\n",
            "Image RAW/Tapir_Lowland_3/725f3d62d3dd11ea91590242ac1c0002_.jpg was predicted as Usable and could be classified.\n",
            "\n",
            "Image RAW/Puma_4/af9fb6cad3dd11ea91590242ac1c0002_.jpg was predicted as Usable and could be classified.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}